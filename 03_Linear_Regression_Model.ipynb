{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03_Linear_Regression_Models\n",
    "In this notebook, we will see how to define simple linear regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T10:36:09.884569Z",
     "start_time": "2017-08-04T10:36:09.465810Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn # Basic Neural Network Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T10:36:43.430060Z",
     "start_time": "2017-08-04T10:36:43.104472Z"
    }
   },
   "outputs": [],
   "source": [
    "# Needs for Ploting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T10:37:15.655106Z",
     "start_time": "2017-08-04T10:37:15.403452Z"
    }
   },
   "outputs": [],
   "source": [
    "# Toy dataset\n",
    "x_train = torch.tensor([[3.3], [4.4], [5.5], [6.71], [6.93], [4.168], \n",
    "                        [9.779], [6.182], [7.59], [2.167], [7.042], \n",
    "                        [10.791], [5.313], [7.997], [3.1]])\n",
    "\n",
    "y_train = torch.tensor([[1.7], [2.76], [2.09], [3.19], [1.694], [1.573], \n",
    "                        [3.366], [2.596], [2.53], [1.221], [2.827], \n",
    "                        [3.465], [1.65], [2.904], [1.3]])\n",
    "\n",
    "plt.scatter(x_train.numpy(), y_train.numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Models\n",
    "The simplest linear model for regression is one that involves a linear combination of the input variables\n",
    "$\\mathbf{y}^{T} = \\mathbf{x}^{T}\\mathbf{W} + \\mathbf{b}$, $\\mathbf{x} \\in \\mathbb{R}^{n}, \\mathbf{y} \\in \\mathbb{R}^m, \\mathbf{W}^{n \\times m}, \\mathbf{b}^{m}$.\n",
    "\n",
    "\n",
    "### Define Linear Regression Models\n",
    "In PyTorch, you can define your weight matrix for linear regression in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "input_size = 1\n",
    "output_size = 1\n",
    "\n",
    "# Weight Matrix\n",
    "W = torch.rand(input_size, output_size)\n",
    "# bias vector\n",
    "b = torch.zeros(output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can compute the linear regression ouput using the above weight matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myLinear(input):\n",
    "    return input.mm(W) + b\n",
    "\n",
    "myLinear(x_train).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function and Optimization\n",
    "A loss function takes the (output, target) pair, and computes a value that estimates how far away the output is from the target.\n",
    "\n",
    "There are several different loss functions for linear regression, but we use the Mean Squared Error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss\n",
    "def myMSE(output, target):\n",
    "    return torch.mean((output-target)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furtheremore, we use the Gradient Descent method for optimization.\n",
    "To do so, we compute the gradient of MSE with respect to the weight matrix $\\mathbf{W}$ and the bias vector $\\mathbf{b}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization\n",
    "def myGradientW(input, output, target):\n",
    "    return 2 * (output-target).view(-1).dot(input.view(-1)) / len(output)\n",
    "\n",
    "def myGradientb(output, target):\n",
    "    return torch.mean(2 * (output-target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T10:42:46.787808Z",
     "start_time": "2017-08-04T10:42:24.384830Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "num_epochs = 60\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    # Compute the prediction(output) of your linear regression model\n",
    "    output = myLinear(x_train)\n",
    "    loss = myMSE(output, y_train)\n",
    "    \n",
    "    # Compute the gradient w.r.t W and b, respectively.\n",
    "    gradientW = myGradientW(x_train, output, y_train)\n",
    "    gradientb = myGradientb(output, y_train)\n",
    "    \n",
    "    # Stochastic Gradient Descent\n",
    "    W -= learning_rate * gradientW\n",
    "    b -= learning_rate * gradientb\n",
    "    \n",
    "    if (epoch+1) % 5 == 0:\n",
    "        print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction (Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T10:43:19.494625Z",
     "start_time": "2017-08-04T10:43:19.485753Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the graph\n",
    "predicted = myLinear(x_train).detach().numpy()\n",
    "plt.plot(x_train.numpy(), y_train.numpy(), 'ro', label='Original data')\n",
    "plt.plot(x_train.numpy(), predicted, label='Fitted line')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Module with PyTorch Libraries\n",
    "\n",
    "In fact, PyTorch supports all the above functions in the `torch.nn` package and `torch.optim` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "input_size = 1\n",
    "output_size = 1\n",
    "learning_rate = 0.001\n",
    "num_epochs = 60\n",
    "\n",
    "# Linear regression model\n",
    "model = nn.Linear(input_size, output_size)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # Forward pass\n",
    "    output = model(x_train)\n",
    "    loss = criterion(output, y_train)\n",
    "    \n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 5 == 0:\n",
    "        print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the graph\n",
    "predicted = model(x_train).detach().numpy()\n",
    "plt.plot(x_train.numpy(), y_train.numpy(), 'ro', label='Original data')\n",
    "plt.plot(x_train.numpy(), predicted, label='Fitted line')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(1)    # reproducible\n",
    "\n",
    "# view data\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.scatter(x_train.data.numpy(), y_train.data.numpy(), color = \"blue\")\n",
    "plt.title('Regression Analysis')\n",
    "plt.xlabel('Independent varible')\n",
    "plt.ylabel('Dependent varible')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is from http://bit.ly/2YS8qg2\n",
    "\n",
    "# Linear regression model\n",
    "model = nn.Linear(input_size, output_size)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "my_images = []\n",
    "fig, ax = plt.subplots(figsize=(12,7))\n",
    "\n",
    "# train the network\n",
    "for t in range(num_epochs):\n",
    "  \n",
    "    prediction = model(x_train)     # input x and predict based on x\n",
    "\n",
    "    loss = criterion(prediction, y_train)     # must be (1. nn output, 2. target)\n",
    "\n",
    "    optimizer.zero_grad()   # clear gradients for next train\n",
    "    loss.backward()         # backpropagation, compute gradients\n",
    "    optimizer.step()        # apply gradients\n",
    "    \n",
    "    # plot and show learning process\n",
    "    plt.cla()\n",
    "    ax.set_title('Regression Analysis', fontsize=35)\n",
    "    ax.set_xlabel('Independent variable', fontsize=24)\n",
    "    ax.set_ylabel('Dependent variable', fontsize=24)\n",
    "    ax.set_xlim(2.0, 11.0)\n",
    "    ax.set_ylim(1.0, 3.8)\n",
    "    ax.scatter(x_train.detach().numpy(), y_train.detach().numpy(), color = \"blue\")\n",
    "    ax.plot(x_train.detach().numpy(), prediction.detach().numpy(), 'g-', lw=3)\n",
    "    ax.text(9.0, 1.4, 'Step = %d' % t, fontdict={'size': 24, 'color':  'red'})\n",
    "    ax.text(9.0, 1.2, 'Loss = %.4f' % loss.detach().numpy(),\n",
    "            fontdict={'size': 24, 'color':  'red'})\n",
    "\n",
    "    # Used to return the plot as an image array \n",
    "    # (https://ndres.me/post/matplotlib-animated-gifs-easily/)\n",
    "    fig.canvas.draw()       # draw the canvas, cache the renderer\n",
    "    image = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n",
    "    image  = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "\n",
    "    my_images.append(image)\n",
    "    \n",
    "   \n",
    "# save images as a gif    \n",
    "imageio.mimsave('/content/drive/My Drive/line_1.gif', my_images, fps=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
